ğŸ‡®ğŸ‡¹ Bari Translator & Info App

Un progetto che utilizza Ollama, LLM locali, Python e Gradio per tradurre testi su Bari e rispondere a domande sulla cittÃ .

ğŸ“Œ Descrizione del progetto

Questa applicazione fornisce:

Traduzione automatica dallâ€™italiano verso inglese e russo (cirillico)

Informazioni sulla cittÃ  di Bari basate su un modello LLM locale

Interfaccia web semplice e moderna tramite Gradio

Il progetto funziona totalmente offline, usando un modello LLM ospitato in locale tramite Ollama.

âš™ï¸ Tecnologie utilizzate
Tecnologia	Ruolo
Python 3.11	Linguaggio principale
Gradio	Interfaccia web
Ollama	Server locale per LLM
Modelli Llama 3.1 locali	Traduzione e risposte
Docker (opzionale)	Distribuzione facilitata
ğŸ“ Struttura del progetto
progetto/
â”‚â”€â”€ webapp.py          # Interfaccia Gradio + routing
â”‚â”€â”€ translator.py      # Comunicazione con Ollama
â”‚â”€â”€ Dockerfile         # (Opzionale) containerizzazione
â”‚â”€â”€ README.md

ğŸ§  Come funziona
1ï¸âƒ£ Traduzione

Il file translator.py invia un prompt controllato al modello:

prompt = f"""
Translate the following Italian text into English and Russian.
Italian:
{text}

Output format:
English: <eng>
Russian: <rus>
"""


Ollama risponde e il programma estrae le traduzioni in maniera affidabile e senza inventare contenuti.

2ï¸âƒ£ Informazioni su Bari

La funzione ask_about_bari() usa un prompt dedicato e fornisce risposte brevi e corrette, sempre basate su un modello locale.

3ï¸âƒ£ Interfaccia Gradio

webapp.py costruisce unâ€™interfaccia moderna:

casella di input

pulsante "Traduci"

pulsante "Info su Bari"

output in box separati

tema personalizzato

emoticon â€œin stile Bariâ€ ğŸ™â›µğŸŒŠ

â–¶ï¸ Avvio dellâ€™app

Assicurati che Ollama sia avviato e che il modello sia disponibile:

ollama run bari-translator
ollama run bari-guide


Poi esegui:

python webapp.py


Apri il browser su:

http://127.0.0.1:7860

ğŸ³ (Opzionale) Avvio con Docker

Costruire lâ€™immagine:

docker build -t bari-app .


Eseguire il container:

docker run -p 7860:7860 -e OLLAMA_HOST="host.docker.internal:11434" bari-app

ğŸ“ Requisiti

Python â‰¥ 3.10

Ollama installato

Un modello locale, es.:

bari-translator

bari-guide

pip install gradio requests